---
title: "Joining several data frames with `dplyr`"
author: "Silvie Cinkov√°"
date: 2025-08-09
echo: true
shift-heading-level-by: -1
format:
  revealjs:
    plugins: [notes]
    toc: true
    slide-number: true
    notes: true
    pdf-export: true
    css: atrium.css
    chalkboard: false
    scrollable: true
    code-block-height: 650px
    echo: true
    #output-location: slide
    preview-links: auto
  pdf:
    toc: true
    number-sections: true
    include-in-header: atrium.tex
  html:
    toc: true
    number-sections: true
    css: atrium.css
    embed-resources: true
---

## Join tables by a shared column

![](images_ATRIUM/SQL-table-schema-showing-the-relations-between-the-tables-in-the-complete-editing_W640.jpg)

::: notes
-   Relational databases: tables connected by shared columns. Useful with big datasets evolving in time, in separate places, etc. Two main assets:

    1)  A change propagates automatically to all places where relevant
    2)  On-demand tables generated by queries (variability depends on how smart the connections between tables are).

-   The figure models how Wikipedia administrators record the history of edits in a relational database. Each of the squares represents one table. The rows represents columns with their names. So, the top right table named `page` lists one Wikipedia page in each row. Its columns are called `id`, `title`, `namespace`, `creation\_date`, `last\_edit\_date`, and `total\_edits`. In the `pagecategory` table, each observation is a combination of the ID of a page and a Wikipedia category. These two tables are connected with a red arrow. It matters which table columns (which look as rows here in this scheme) these arrows exactly connect.

-   The rows at the start and end of the arrows form a pair. They can have different names, but they describe the same thing in the data. Here these are page IDs. In the `pages` table, the `id` column is unique for each observation. It is the **primary key** of this table. Whenever I want to relate another table to this one, I must include a column with the page IDs. In each of these tables, the column of the related page IDs is called **foreign key**. The foreign key values need not bee unique. In our context, each page can be in multiple Wikipedia categories at the same time (e.g. "capitals", "cities", and "administration units"). If the page were about Prague, which is a capital and hence a city and administration unit, the ID of the Prague page would occur three times in the `pageincategory` table. The relation holds also the other way round: one category can describe many pages. In real database schemes, you would see different types of arrows that would tell you exactly how many source items can connect to how many target items. This figure does not quite follow this notation, so we can only tell by common sense.

When you want to get a table of titles of the pages and the names of the categories they belong to, you call a function that connects matching rows from the both tables by matching together the values of the primary key and the foreign key. By this way, you do not need to worry about how the rows are arranged in either table.

Designing the architecture of a relational database is a skill in its own right. You need not know exactly how to design a relational database, but you will often need to connect tables from sources that are formed so.

I have adopted this image from this academic paper: <https://arxiv.org/pdf/1512.03523>. I have corrected the yellow arrow from `userincategory` to `category` to point from `category_id` instead of from `user_id`.
:::

## Revision performed by a user

![](images_ATRIUM/SQL-revision-user.jpg)

::: notes
You can even look up things within one single table: look at the `revision` table: `parentid`: the id of the previous revision - to look up on a different row in the same table. I guess that a parent revision is simply the revision event immediately preceding in time.

-   Revision table with columns `id`, `page_id`, `user_id`,`timestamp`, , `parentid`,`text`.
-   primary key: unique `id` of each revision.
-   `page_id` foreign key - turquoise arrow leads to a *page* table, to its primary key (probably called `id` but potentially anything else)
-   `user_id` foreign key - purple arrow leads to a *user* table
-   `timestamp`: when the revision took place

The scheme does not say whether the parent revision must be one on the same Wikipedia page or rather one performed by the same user. This would also be a design decision: whether you want to be able to track revision of pages or rather the activities of the users, or both. Anyway, from this table, you can connect to both users and pages, so you can generate a table with titles and names of both for each revision.
:::

## `gapminder`

```{r}
#| echo: false
#| warning: false
#| message: false
if (require(fuzzyjoin) == FALSE) {
  install.packages(fuzzyjoin)
  }
if (require(stringdist) == FALSE) {
  install.packages(stringdist)
}
library(dplyr)
library(glue)
library(gapminder)
library(readr)
library(stringr)
library(magrittr)
library(stringdist)
library(fuzzyjoin)
slice_head(gapminder, n = 3)
```

::: notes
You can join tables with `dplyr`. So far, we have worked quite a lot with diverse tables from Gapminder.org. You correctly anticipate that Gapminder.org stores its data in relational databases. Their tables are made for you to freely combine information across different tables.

In this session, we will enrich our familiar `gapminder` dataset with additional information from a table of unique countries. We will call that other table `geo`. This table contains many columns, so we will only select a few to keep this demonstration overseeable.

::: callout-tip
::: notes
Did you know that `readr` allows you to select columns before you even load the data? When you know their names, that is.
:::
:::
:::

## `geo` {.smaller}

```{r}
geo <- read_csv(glue("https://raw.githubusercontent.com/open-numbers/",
                     "ddf--gapminder--fasttrack/master/",
                     "ddf--entities--geo--country.csv"))
geo <- geo %>% select(country, name, main_religion_2008, income_3groups, world_4region)
glimpse(geo)
```

::: notes
Now we have a data frame called `geo`. It lists 273 countries, each only once, and for each country it gives us its dominant religion (snapshot taken in 2008) and to which income group it belongs. The income groups are Gapminder's own design and obviously refer to the time of creating this dataset. The countries are encoded by their names (column `name`) and by the abbreviations of these names (column `country`).

::: callout-important
The `gapminder` data frame does not use abbreviations for country names. But even more importantly, its `country` column does not correspond to `country` but to `name` in the `geo` data frame. This is something to keep in mind when we try to join these two tables!
:::
:::

## Countries in `geo` vs. `gapminder` {.smaller}

```{r}
unique(geo$name) %>% length()
```

```{r}
unique(gapminder$country) %>% length()
```

::: notes
When we want to join `geo` and `gapminder`, we can apparently use `geo`'s `name` and `gapminder`'s `country` as the *primary key - foreign key* pair.

The first question you must ask when you want to join two tables by a pair of keys is how much overlap they have at all. `geo` contains many more countries than `gapminder`, so much is clear. But it is not given that all of its countries are listed in `geo`! Therefore we do this quick check.

::: callout-note
::: notes
You could as well call `distinct` and `pull` on each, but this base-R way is shorter. It accesses a data frame column as a vector and calls the `unique` function, which acts on vectors like `dplyr::distinct` on data frames.
:::
:::
:::

## Little overlap in key column values? {.smaller}

```{r}
setdiff(gapminder$country, geo$name) 
```

```{r}
setdiff(geo$name, gapminder$country) %>% length()
```


::: notes

`setdiff` tells you which elements of the first vectors are not in the second vector. We see that the `gapminder` data frame is not a full subset of the `geo` data frame. When we enrich `gapminder` with the information from `geo`, some values will be missing. This has no programmatic solution. This is your design decision. Drop these seven countries from `gapminder` because you don't get the additional information, or live with `NA`s in the new columns? Or you even find the `geo` table more important and only want to enrich with `gapminder`'s `pop`, `lifeExp`, and `gdpPercap` in a given year? For each of your possible decisions, `dplyr` comes with a dedicated `_join` function.

:::

## Control key selection

![](images_ATRIUM/joins.png){width="50%"}


::: notes

When blue and yellow mix, they give green. This scheme depicts the possible joining outcomes. The yellow area represents the `gapminder` data, the blue the `geo` data, and the green area the resulting new table.

1.  With `inner_join` you join just the rows that match in both tables. So you will not have any new empty values.
2.  The `left_join` and `right_join` functions are two different perspectives of the same thing, what exactly each does obviously depends on the order in which you feed in the tables. If we always feed `gapminder` as first (the `x` argument) and `geo` second (`y`), left join will keep all rows in `gapminder` and match them to `geo`. We know that seven countries will not be matched, which will result in 7 times 12 rows with `NA` values in the new columns containing the abbreviation, main religion in 2008, and the income group. The twelve comes from the number of observations (remember, 1952 to 2007, in five-year intervals).
3.  With `right_join`, we will get a monstrous table of all `geo's countries`, and the ones that match `gapminder`, will be matched twelve times each, with a warning for "many-to-many" relations occurring. The new table is going to have four new columns: `year`, `pop`, `lifeExp`, and `gdpPercap`. They will be filled with `NA` except in the rows with countries whose names matched across both tables, and the seven countries from `gapminder` will not appear in the new table.
4.  With `full_join`, no row will be deleted, but there will be `NA` in all mismatched rows.
5.  All these tables are going to have the same columns.
:::

## `gapminder` Europe 2007 {.smaller}

```{r}
gapminder_europe <- gapminder %>% 
  filter(continent == "Europe", year == 2007) %>%
  select(!c(continent, year))
glimpse(gapminder_europe)
```

::: notes
We make a subset of `gapminder` to keep the data small. Just European countries in 2007 and we drop the columns `continent` and `year` because they are all equal.
:::

## European subset of `geo` {.smaller}

```{r}
geo_europe <- geo %>% filter(world_4region == "europe") %>% 
  select(!world_4region)
glimpse(geo)
```

## Preferred `gapminder`, intersection 

```{r}
dplyr::inner_join(x = gapminder_europe, y = geo_europe, 
                  by = c("country" = "name")) 
```


::: notes

We would like to add information from `geo` to `gapminder_europe`.

The resulting data frame is going to inherit only the rows with matching country names from both.

The `_join` functions in `dplyr` always need a first data frame (`x`), a second data frame (`y`), and a vector of column names that provide the key pair(s) in the argument called `by`. The whole thing reads: "Join `x` with `y` by this vector of key pairs." Each pair contains the name of the key column in `x` and the name of the corresponding column in `y`, in exactly this order. Relational databases are designed to answer most queries with just one pair, but sometimes you need several to uniquely identify observations in at least one of the data frames.

Mind the quotes in the column names in `by`. This time they are mandatory.

There were 30 countries in `gapminder_europe`, but the resulting data frame has only 29 rows. One country was missing in `geo_europe`, although it is so much longer than `gapminder_europe`. We will find out later which. You can see an `NA` in the fourth row, 6th column. This has nothing to do with joining; it was like this in the original `geo_europe` data frame.

Look closely at the names of the columns. Can you see `country` and `country.y`? The former is from `gapminder`, the latter from `geo_europe`. Column names must remain unique, therefore `dplyr` adds suffixes to duplicate names. Typically, the duplicate column name from the `x` data frame gets the suffix `.x` and the other one `.y`. You can replace them with your own suffixes in the `suffix` argument. In this case, only the one from the `y` data frame got the suffix. This is because it was used as a `by` column. By default, the key column from `y` disappears and only the `x` key column stays. You can also fiddle with this in a dedicated argument `keep`. So, in this case, the `x` `country` column stayed, the paired `name` column from `y` vanished, and then `dplyr` spotted another `country` column among the columns inherited from `y`. The function is just written in such a way that it does only put the suffix on one, when the other one was used as key. Do not ponder on it, just remember.

:::


## Keep `gapminder` intact, no matter what. {.smaller}

One country gets `NA` in `geo_europe` columns.

```{r}
dplyr::left_join(x = gapminder_europe, y = geo_europe,
                 by = c("country" = "name")) 

```

## Which is missing? {.smaller}

-   country mismatch $\rightarrow$ `is.na(country.y)`

```{r}
dplyr::left_join(x = gapminder_europe, y = geo_europe,
                 by = c("country" = "name")) %>%
  filter(is.na(country.y))
```

## Focus on `geo_europe` {.smaller}

```{r}
dplyr::right_join(x = gapminder_europe, y = geo_europe,
                 by = c("country" = "name")) 
```

## Mismatches in `geo_europe` {.smaller}

```{r}
dplyr::right_join(x = gapminder_europe, y = geo_europe,
                 by = c("country" = "name")) %>% 
  filter(is.na(lifeExp) | is.na(pop) | is.na(gdpPercap))
```

::: notes
We must look for a column that was not in `geo_europe`. The country column now is the result of `country` and `name`, so it will contain all countries from `geo_europe` but will have dropped `United Kingdom`, which was only in `gapminder_europe`. Any of the numeric columns from `gapminder` will help us though.
:::

## Get what you can {.smaller}

```{r}
dplyr::full_join(x = gapminder_europe, y = geo_europe,
                 by = c("country" = "name"))
```

::: notes
The full join is going to contain all country names from both data frames, with NA where they mismatched.
:::

## `anti_join` detects mismatches instantly {.smaller}

-   like `setdiff` in vectors

```{r}
anti_join(x = gapminder_europe, y = geo_europe,
                 by = c("country" = "name"))
```

## `anti_join` the other way round {.smaller}

```{r}
anti_join( x = geo_europe, y = gapminder_europe,
                 by = c( "name" = "country"))
```

::: notes
`anti_join`: Filter rows of `x` that are not matched in `y`.
:::

## `semi_join` detects matches {.smaller}

```{r}
semi_join( x = geo_europe, y = gapminder_europe,
                 by = c( "name" = "country"))
```

::: notes
Filter rows of `x` that are matched by `y`. In this context, the countries are going to be the same, no matter in which order you name the data frames, but you will of course get the rows of the one you fed in as `x`. It can be helpful to look at both sides, especially when you know that you have a lot of `NA` across the columns of both. If you have to opt for either left or right join, you can at least choose that with less missing data.\
:::

## When your observations are not unique {.smaller}

```{r echo=FALSE}
maths <- tibble(#id = c("a01", "a02", "a03", "a04"), 
                name = c("John Smith", "Mary Brown", 
                         "John Smith", "Helene Field"), 
                
                birthplace = c("Honolulu", "Milan", "Prague", "Beijing"), 
                math_test = c(72, 40, 25, 91)
                )

social_sciences <- tibble(#id =  c("a02", "a01", "a03", "a04"), 
                          name = c("Mary Brown", "John Smith", "John Smith",
                                   "Helene Field"), 
                          birthplace = c("Milan", "Honolulu", 
                                         "Prague", "Beijing"), 
                          soc_test = c(12, 5, 76, 49)
                          
                          )
```

## The two tibbles: math {.smaller}

```{r}
maths
```

## The two tibbles: social sciences {.smaller}

```{r}
social_sciences
```

::: notes
Students' grades in two courses. You would like to have both exams in the same table. Are the students uniquely identified?
:::

## Possible rescue: unique by several columns {.smaller}

```{r}
left_join(maths, social_sciences, by = (c("name", "birthplace")))
```

## No chance to join {.smaller}

If you cannot find anything that makes them unique.

```{r warning=TRUE}
maths2 <- select(maths, -birthplace)
social_sciences2 <- select(social_sciences, !birthplace)
left_join(maths2, social_sciences2, by = "name")
```

::: notes
Note John Smith occurring four times - all possible combinations get generated.
:::

## `dplyr::join` help

explore the arguments

-   `relationship`

-   `multiple`

-   `unmatched`

## Data with typos in the key column(s)

-   libraries `fuzzyjoin` along with `stringdist` (used by `fuzzyjoin`)

-   DataCamp course **Intermediate Regular Expressions in R \> Similarities Between Strings**

::: notes
You should only know that there are ways to cope with strings in columns that do not match completely. Only read further if you are particularly interested.
:::

## JRC Names

Steinberger Ralf, Bruno Pouliquen, Mijail Kabadjov, Jenya Belyaeva & Erik van der Goot (2011).**JRC-Names: A freely available, highly multilingual named entity resource**. Proceedings of the 8th International Conference Recent Advances in Natural Language Processing (RANLP). Hissar, Bulgaria, 12-14 September 2011.

```{r echo=FALSE, eval=FALSE}
library(data.table)
jrc <- fread(file = "datasets_ATRIUM/JRC_Names/JRC_Names.tsv", skip = 1, col.names = c("id", "PersOrg", "name"), drop=3) 
jrc_latin <- jrc[str_detect(name, regex("^(\\p{IsLatin}|\\p{IsPunctuation}|\\p{IsSymbol}|\\p{IsMark})+$"))]
jrc_count <- jrc_latin[, n := .N, by = id]
jrc_latin %>% write_tsv("datasets_ATRIUM/JRC_Names/jrc_latin.tsv")
jrc_lac <- jrc_latin[n == 4]
jrc_lac %>% write_tsv("datasets_ATRIUM/jrc_latin_4.tsv")
jrc_lac %<>% group_by(id) %>% mutate(index_id = 1:n()) %>% ungroup()
jrc_1 <- jrc_lac %>% filter(index_id == 1) %>% arrange(id) %>% slice(1:20)
jrc_2 <- jrc_lac %>% filter(index_id == 2) %>% arrange(id) %>% slice(1:20)
jrc_3 <- jrc_lac %>% filter(index_id == 3) %>% arrange(id) %>% slice(1:20)
jrc_4 <- jrc_lac %>% filter(index_id == 3) %>% arrange(id) %>% slice(1:20)
write_tsv(jrc_1, "datasets_ATRIUM/JRC_Names/jrc_1.tsv")
write_tsv(jrc_2, "datasets_ATRIUM/JRC_Names/jrc_2.tsv")
write_tsv(jrc_3, "datasets_ATRIUM/JRC_Names/jrc_3.tsv")
write_tsv(jrc_4, "datasets_ATRIUM/JRC_Names/jrc_4.tsv")
```
```{r}
jrc_1 <- read_tsv("datasets_ATRIUM/JRC_Names/jrc_1.tsv")
jrc_2 <- read_tsv("datasets_ATRIUM/JRC_Names/jrc_2.tsv")
jrc_3 <- read_tsv("datasets_ATRIUM/JRC_Names/jrc_3.tsv")
jrc_4 <- read_tsv("datasets_ATRIUM/JRC_Names/jrc_4.tsv")
```

## JRC Person Names 
- persons with 4 spellings of their names 
- 2 tables, 20 rows, 
  - equal pers IDs, different spelling
- test different fuzzy join metrics 

::: notes
Watch the number of rows in inner join. 
Sensitivity (recall): how many it catches of those to catch: the longer table the better
Specificity (precision): how many of those caught were correct (how much noise): check that their ids match.

:::


## JRC each table {.smaller}
```{r}
jrc_1 %>% slice_head(n = 5) %>% select(!c( n, index_id, starts_with("PersOrg")))
```


```{r}
jrc_2 %>% slice_head(n = 5) %>% select(!c(n, index_id, starts_with("PersOrg")))
```



## Matching on Levenschtein Distance {.smaller}

```{r}
joinJRC_lv <- fuzzyjoin::stringdist_inner_join(x = jrc_1, y = jrc_2, 
distance_col = "distance", by = "name", ignore_case = TRUE,
method = "lv",  max_dist = 2) %>% 
  relocate(name.x, name.y, distance) %>% select(!c(n.x, n.y, index_id.x, starts_with("PersOrg")))
joinJRC_lv
```


## Matching on cosine distance between qgrams {.smaller}

```{r eval=TRUE}
joinJRC12_cosine <- fuzzyjoin::stringdist_inner_join(x = jrc_1, y = jrc_2, distance_col = "distance",
          by = "name", ignore_case = TRUE, 
           method = "cosine",
          q = 1,
          max_dist = 0.15,
          ) %>% relocate(name.x, name.y, distance) %>% select(!c(n.x, n.y, index_id.x, starts_with("PersOrg")))
joinJRC12_cosine
```

## Matching on Jaccard distance {.smaller}

```{r eval=TRUE}
joinJRC12_jaccard <- fuzzyjoin::stringdist_inner_join(x = jrc_1, y = jrc_2,
distance_col = "distance",  by = "name", ignore_case = TRUE, method = "jaccard",
          q = 1, max_dist = 0.18) %>% 
  relocate(name.x, name.y, distance) %>% select(!c(n.x, n.y, index_id.x, starts_with("PersOrg")))
joinJRC12_jaccard
```
